# æ•°æ®è¯»å–åŠåŸºæœ¬å¤„ç†
import pandas as pd
import numpy as np
from sklearn import linear_model
from sklearn.model_selection import cross_val_score,KFold,cross_validate
from sklearn import metrics

# è¯»å…¥æ•°æ®
df = pd.read_csv("FE_day_T.csv")
#print(df.head())

# æ•°æ®åˆ†ç¦»
y = df['cnt']
X = df.drop('cnt', axis = 1)

result = {}
k = []
# æœ€å°äºŒä¹˜
lr = linear_model.LinearRegression()
def linear_score(X,y):
    X = X.values
    y = y.values

    # ğ¾æŠ˜äº¤å‰éªŒè¯æ•°æ®åˆ’åˆ†
    fold = KFold(5, shuffle=False)  # åˆ‡åˆ†5éƒ¨åˆ†


    i = 0
    for train_index, test_index in fold.split(X, y):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]

        lr.fit(X_train, y_train)
        y_pred = lr.predict(X_test)

        result[i] = lr.coef_
        k.append(metrics.mean_squared_error(y_test, y_pred))


#        score = lr.score(X_test, y_test)
#        print(score)
#        print("MAE:{0}".format(metrics.mean_absolute_error(y_test, y_pred)))
        print("RMSE:{0}".format(k[i]))
        i = i+1


linear_score(X, y)

print(result[k.index(min(k))])

#lr = linear_model.LinearRegression()
#cross_result = cross_validate(lr, X, y, None, "neg_mean_squared_error", 5, return_train_score = False)
#print(cross_result.keys())
#print(cross_result['test_score'])